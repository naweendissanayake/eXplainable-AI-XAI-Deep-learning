The objective of eXplainable AI (XAI)/Deep learning is to design and develop methods
that can be used to understand how these systems produce their decisions. Explanation
methods aid in the unmasking of such spurious correlations and biases in the model
or data and also help in explaining the failures of the system. Inspecting the recent
trends, the major methods that exist for the explanation of a CNN can be classified
into two major categories of (i) black-box methods and (ii) white-box methods. Blackbox methods are typically those that inspect the output of the network by changing
the input to draw conclusions and insights. They do not require any knowledge about
the model like the different layers, parameters or different connections amongst the
layers. In contrast, the methods of XAI which access internal model parameters and
structure are called white-box approaches. These methods have been designed to study
the network architecture and the parameters that have been learnt during training to
perform attribution of the results of the network. Such methods have been intensively
developed during recent years, but universal solutions have not been found, yet.
